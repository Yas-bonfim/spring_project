{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Trabalho_Final_Caio_Amorim_Gabriel_Sete_Gustavo_Oliveira_Yasmin_Bonfim",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install kaggle #Instalando a biblioteca do Kaggle para posteriormente baixar o dataset que irá ser utilizado"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcjtDMm8YAfC",
        "outputId": "c5e90c27-c419-4755-f8da-3f775d00ecc1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Função para importar o Token (chave de acesso) do Kaggle para baixar diretamente do colab\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "outputs": [],
      "metadata": {
        "id": "uBRAbio3qYdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "outputs": [],
      "metadata": {
        "id": "hHYAa-WC7S2o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!kaggle datasets download -d rishitchs/final-flowers-course-project-dataset #Instalação do Dataset"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading final-flowers-course-project-dataset.zip to /content\n",
            " 96% 410M/426M [00:02<00:00, 140MB/s]\n",
            "100% 426M/426M [00:02<00:00, 165MB/s]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeD6IsQfZfMh",
        "outputId": "a13fcf9c-c67b-4158-888d-3ef3c16c9584"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Importando bibliotecas necessárias\r\n",
        "\r\n",
        "from keras.preprocessing import image\r\n",
        "from zipfile import ZipFile\r\n",
        "import pandas as pd \r\n",
        "from pathlib import Path\r\n",
        "import os\r\n",
        "import timeit\r\n",
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from keras.layers import Conv2D,Dense,Dropout,Input,Flatten,MaxPooling2D\r\n",
        "from keras.models import Model\r\n",
        "from keras.utils import plot_model,to_categorical\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras import Sequential\r\n",
        "from keras.optimizers import *\r\n",
        "from keras.datasets import cifar10\r\n",
        "from keras.layers import Dropout, BatchNormalization\r\n",
        "from keras.models import Model\r\n",
        "from keras.utils import to_categorical, plot_model\r\n",
        "from collections import Counter\r\n",
        "from keras.backend import clear_session\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "import keras.layers as kl\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "id": "yEZqds1b7bZw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Adicionando o arquivo zip a uma variável\n",
        "arquivo = \"final-flowers-course-project-dataset.zip\"\n",
        "  \n",
        "# Descompactando o arquivo zip\n",
        "with ZipFile(arquivo, 'r') as zip:\n",
        "    zip.printdir()\n",
        "  \n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ],
      "outputs": [],
      "metadata": {
        "id": "7zAfbE0QB1xa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Importando as funções para o data argumentation\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "#Armazenando o Path de cada label para usar na função\n",
        "rose = Path('/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/rose')\n",
        "\n",
        "daisy = Path('/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/daisy')\n",
        "\n",
        "dandelion = Path('/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/dandelion')\n",
        "\n",
        "sunflower = Path('/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/sunflower')\n",
        "\n",
        "tulip = Path('/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/tulip')"
      ],
      "outputs": [],
      "metadata": {
        "id": "UUYuZZtAMmJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Definindo as modificações que serão aplicadas nas imagens\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "#Criando uma função para criar novas imagens a parir da função do data argumentation e já armazenando nas devidas pastas\n",
        "def flower_aug(flower, name, n):\n",
        "  for imagem in flower.glob('*'): \n",
        "    img = load_img(imagem)  \n",
        "    x = img_to_array(img)  \n",
        "    x = x.reshape((1,) + x.shape)  \n",
        "\n",
        "  i = 0\n",
        "  for batch in datagen.flow(x, batch_size=1,\n",
        "                            save_to_dir= flower, save_prefix=name, save_format='jpg'):\n",
        "      i += 1\n",
        "      if i > n:\n",
        "          break\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "mxkjPgnSagvm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "flores = []"
      ],
      "outputs": [],
      "metadata": {
        "id": "VYBxTFcn9NUx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Utilizando a função para cada label \n",
        "flower_aug(sunflower, 'sunflower_aug', 406 )\n",
        "\n",
        "flower_aug(tulip, 'tulip_aug', 166)\n",
        "\n",
        "flower_aug(dandelion, 'dandelion_aug', 48)\n",
        "\n",
        "flower_aug(rose, 'rose_aug', 356)\n",
        "\n",
        "flower_aug(daisy, 'daisy_aug', 331)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FIYte_xrmyOy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Após a criação de novas imagens, utilizamos o glob para percorrer e pegar os arquivos de cada pasta e armazenando em listas em formato de matriz\n",
        "p = Path('/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/')\n",
        "dirs = p.glob('*')\n",
        "image_data = []\n",
        "labels = []\n",
        "image_paths = []\n",
        "labels_dict = {'dandelion':0,'daisy':1,'sunflower':2,'tulip':3,'rose':4}\n",
        "\n",
        "for fold in dirs:\n",
        "  label =str(fold).split('/')[-1]\n",
        "\n",
        "  cnt = 0\n",
        "  print(fold)\n",
        "  for img_path in fold.glob(\"*.jpg\"):\n",
        "    img = image.load_img(img_path, target_size=(64,64))\n",
        "    img_array = image.img_to_array(img)\n",
        "    image_data.append(img_array)\n",
        "\n",
        "    labels.append(labels_dict[label])\n",
        "\n",
        "    cnt +=1\n",
        "  print(cnt)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/sunflower\n",
            "1173\n",
            "/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/dandelion\n",
            "1516\n",
            "/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/tulip\n",
            "1420\n",
            "/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/rose\n",
            "1215\n",
            "/content/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers/daisy\n",
            "1235\n"
          ]
        }
      ],
      "metadata": {
        "id": "X-CJ2rR_Jr3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20aec7af-1dfa-4512-983f-552c2034bef7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(len(image_data),len(labels))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6559 6559\n"
          ]
        }
      ],
      "metadata": {
        "id": "bQolsrVcJodd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fadd7b09-30b4-4a3f-b3e8-08228b9049a6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Definindo nosso X e nosso y\n",
        "X = np.array(image_data)\n",
        "y = np.array(labels)"
      ],
      "outputs": [],
      "metadata": {
        "id": "wMLCeyrCJqos"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Divisão dos dados \n",
        "data = train_test_split(X,y,test_size=0.2, shuffle=True, stratify=y)\n",
        "X_train, X_test, y_train, y_test = data"
      ],
      "outputs": [],
      "metadata": {
        "id": "jYuQkVPnJte9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Plotando as imagens sem reescalar os dados\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(0,9):\n",
        "  plt.subplot(330 + 1 + i)\n",
        "  # plot raw pixel data\n",
        "  plt.imshow(X_train[i])\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "QoE5KKLrvT3V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Plotando as imagens reescalando os dados por 255\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(0,9):\n",
        "  plt.subplot(330 + 1 + i)\n",
        "  # plot raw pixel data\n",
        "  plt.imshow(X_train[i]/255.0)\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y1JwR7VgKghM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Plotando exemplos da Label Rose\n",
        "\n",
        "for flor in flores:\n",
        "  rose = flores[0]\n",
        "image_list = []\n",
        "for filename in rose.glob('*'): \n",
        "    im=Image.open(filename)\n",
        "    image_list.append(im)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9):\n",
        "  plt.subplot(330 + 1 + i)\n",
        "  plt.imshow(image_list[i])\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Tlm7LPOX9EKq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Plotando exemplos da Label Dandelion\n",
        "\n",
        "for flor in flores:\n",
        "  dandelion = flores[1]\n",
        "image_list = []\n",
        "for filename in dandelion.glob('*'): \n",
        "    im=Image.open(filename)\n",
        "    image_list.append(im)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9):\n",
        "  plt.subplot(330 + 1 + i)\n",
        "  plt.imshow(image_list[i])\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "fsYFdmIo9Z2a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Plotando exemplos da Label Sunflower\n",
        "\n",
        "for flor in flores:\n",
        "   sunflower= flores[2]\n",
        "image_list = []\n",
        "for filename in sunflower.glob('*'): \n",
        "    im=Image.open(filename)\n",
        "    image_list.append(im)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9):\n",
        "  plt.subplot(330 + 1 + i)\n",
        "  plt.imshow(image_list[i])\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "B67aEMmF9dM6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Plotando exemplos da Label Tulip\n",
        "\n",
        "for flor in flores:\n",
        "   tulip = flores[3]\n",
        "\n",
        "image_list = []\n",
        "for img in tulip.glob('*'): \n",
        "    im=Image.open(img)\n",
        "    image_list.append(im)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9):\n",
        "  plt.subplot(330 + 1 + i)\n",
        "  plt.imshow(image_list[i])\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "AVorh9S-9jJy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Plotando exemplos da Label Daisy\n",
        "\n",
        "for flor in flores:\n",
        "   daisy = flores[4]\n",
        "image_list = []\n",
        "for img in daisy.glob('*'): \n",
        "    im=Image.open(img)\n",
        "    image_list.append(im)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9):\n",
        "  plt.subplot(330 + 1 + i)\n",
        "  plt.imshow(image_list[i])\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "2pq69nDp97_s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Verificando a quantidade de dados para cada label\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.bar(Counter(y_test).keys(), Counter(y_test).values(), align='center', alpha=0.5)\n",
        "plt.ylabel('Instancias')\n",
        "plt.xlabel('Classe')\n",
        "plt.title('Instancias por classe')\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Zg0PNv5hL4_6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Tratando os dados para o treino\n",
        "#OBS: Comentar esse trecho se for rodar o K-Fold\n",
        "\n",
        "# X_train = X_train.astype('float32')\n",
        "# X_test = X_test.astype('float32')\n",
        "\n",
        "# X_train /= 255\n",
        "# X_test /= 255\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5247 train samples\n",
            "1312 test samples\n"
          ]
        }
      ],
      "metadata": {
        "id": "u39vKGa6NjZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c16f5e-9a08-465b-ae03-0c647ddd07ac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Verificando a quantidade de classes\n",
        "\n",
        "num_classes = len(Counter(y_test))\n",
        "num_classes"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ],
      "metadata": {
        "id": "j2HgkkDNOSVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61622d04-32d9-44d1-e6b2-55e448d61e7e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Fazendo o One Hot Encoder para as variáveis y\n",
        "#OBS: Comentar esse trecho se for rodar o K-Fold\n",
        "\n",
        "# y_train = to_categorical(y_train, num_classes)\n",
        "# y_test = to_categorical(y_test, num_classes)"
      ],
      "outputs": [],
      "metadata": {
        "id": "6uh9-wZnOeKL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Função do modelo\n",
        "\n",
        "def get_model(nb_classes = 5, input_shape = (64,64,3)):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(kl.Input(input_shape))\n",
        "  model.add(kl.Conv2D(64, (3,3), padding = 'same',activation='relu'))\n",
        "  model.add(kl.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(kl.Conv2D(96, (3,3),padding = 'same',activation='relu'))\n",
        "  model.add(kl.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(kl.Dropout(0.2))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(kl.Conv2D(512, (3,3),padding = 'same',activation='relu'))\n",
        "  model.add(kl.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(kl.Dropout(0.3))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(kl.Conv2D(64, (3,3),padding = 'same',activation='relu'))\n",
        "  model.add(kl.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(kl.Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(kl.Conv2D(32, (3,3),padding = 'same',activation='relu'))\n",
        "  model.add(kl.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(kl.Conv2D(15, (2,2)))\n",
        "  model.add(kl.Flatten())\n",
        "  model.add(kl.Dense(1024, activation='relu'))\n",
        "  model.add(kl.Dropout(0.3))\n",
        "  model.add(kl.Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "  # Apresentando a estrutura do modelo\n",
        "  model.summary()\n",
        "\n",
        "  image = tf.expand_dims(X_train[1], 0)\n",
        "\n",
        "  # Compilando o modelo\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=Adam(), \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Retornando o modelo\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "tjxiKgzBOsoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Visualizando o modelo\n",
        "\n",
        "model = get_model(num_classes, X_test.shape[1:])\n",
        "plot_model(model, show_dtype=True, show_shapes=True, show_layer_names=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "oC5NcbyBOyFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Importando a biblioteca para uma visualização do modelo por outro ângulo\n",
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "\n",
        "visualkeras.layered_view(model)"
      ],
      "outputs": [],
      "metadata": {
        "id": "h-9O4tpFNuzi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Quantidade de épocas\n",
        "epochs = 100\n",
        "# Batch size para treinamento\n",
        "bs = 30\n",
        "\n",
        "Treinando o modelo, e armazenando o resultado do treinamento em uma variável\n",
        "hist = model.fit(X_train, y_train,\n",
        "                 epochs = epochs,\n",
        "                 batch_size = bs,\n",
        "                 validation_split=0.20,\n",
        "                 verbose=1)\n",
        "\n",
        "# Computando o tempo para treinar (fim)\n",
        "stop = timeit.default_timer()"
      ],
      "outputs": [],
      "metadata": {
        "id": "3u51y0gMPdOA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred = model.predict(X_test)\n",
        "n_predict = np.argmax(y_pred,axis = 1)\n",
        "n_y_test = np.argmax(y_test, axis = 0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "l7_pwXeN4g9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Criando uma matriz de confusão\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "data = {'y_test':n_y_test,\n",
        "        'pred': n_predict}\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_test','pred'])\n",
        "\n",
        "matriz = pd.crosstab(df['y_test'], df['pred'], rownames=['Realidade'], colnames=['Predições'])\n",
        "print(matriz)"
      ],
      "outputs": [],
      "metadata": {
        "id": "u589NJZN4gJ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Criando o classification report para a comparação de diversos métricas\n",
        "\n",
        "target_names = ['Daisy', 'Dandelion', 'Rose','Sunflower','Tulip']\n",
        "print(classification_report(n_y_test, n_predict, target_names=target_names))"
      ],
      "outputs": [],
      "metadata": {
        "id": "Rd9768wW4lu4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate do modelo\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Gráfico de loss\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.title(f\"Gráfico de Loss - {scores[0]}\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.plot(hist.history['loss'], label=\"loss\")\n",
        "plt.plot(hist.history['val_loss'], label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Gráfico de acurácia\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.title(f\"Gráfico de Acurácia - {scores[1]}\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.plot(hist.history['accuracy'], label=\"accuracy\")\n",
        "plt.plot(hist.history['val_accuracy'], label=\"val_accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "wVLVbeJvRpQ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Chamamos a função StratifiedKFold para realizar um particionamento dos dados durante o treinamento\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=None)\n",
        "\n",
        "hist_scores = []\n",
        "#Separação dos dados do K-flod em treino e teste\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
        "\n",
        "    # print('Fold {}'.format(i))\n",
        "    # print('\\tÍndices para conjunto de treinamento:')\n",
        "    # print('{}'.format(train_index))\n",
        "    # print('\\tÍndices para conjunto de teste:')\n",
        "    # print('{}'.format(test_index))\n",
        "    # print()\n",
        "    \n",
        "#Separação dos dados em treino e teste , e também em x e y\n",
        "    KX_train = X[train_index]\n",
        "    KX_test = X[test_index]\n",
        "    Ky_train = y[train_index]\n",
        "    Ky_test = y[test_index]\n",
        "#Verificar o número de classes presentes\n",
        "    num_classes = 5\n",
        "\n",
        "    KX_train = KX_train.astype('float32')\n",
        "    KX_test = KX_test.astype('float32')\n",
        "#Redimensonamento dos dados \n",
        "    KX_train /= 255\n",
        "    KX_test /= 255\n",
        "#Passamos os dados para o to_categorical \n",
        "    Ky_train = to_categorical(Ky_train, 5)\n",
        "    Ky_test = to_categorical(Ky_test, 5)\n",
        "\n",
        "    # print('Fold {}'.format(i))\n",
        "    # print('\\tDados para conjunto de treinamento:')\n",
        "    # print('{}'.format(X_train))\n",
        "    # print('{}'.format(y_train))\n",
        "    # print('\\tDados para conjunto de teste:')\n",
        "    # print('{}'.format(X_test))\n",
        "    # print('{}'.format(y_test))\n",
        "    # print()\n",
        "\n",
        "\n",
        "\n",
        "    model = get_model(num_classes, KX_test.shape[1:])\n",
        "#treinamento da rede neural com o k-fold\n",
        "    hist = model.fit(KX_train, Ky_train,\n",
        "                 epochs = 30,\n",
        "                 batch_size = 300,\n",
        "                 validation_split= 0.2,\n",
        "                 verbose=1)\n",
        "    #Avaliação do modelo \n",
        "    scores = model.evaluate(KX_test, Ky_test, verbose=0)\n",
        "#Armazenamento do desempenho em uma lista\n",
        "    hist_scores.append(scores)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SNmdGXfLGDEU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#K-Fold com dados\n",
        "df = hist_scores\n",
        "\n",
        "tabela = pd.DataFrame(df, columns=['Loss','Accuracy'])\n",
        "\n",
        "tabela"
      ],
      "outputs": [],
      "metadata": {
        "id": "SSJVyUySapVt"
      }
    }
  ]
}